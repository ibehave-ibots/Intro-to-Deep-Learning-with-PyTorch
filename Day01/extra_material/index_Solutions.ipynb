{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6cb238c6",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Tensors are the core data structure in PyTorch. Through creating and working with tensors, you will learn how tensors are similar to NumPy arrays, but offer additional features for deep learning."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08436467-1efb-4301-9c59-43f7363ca4f8",
      "metadata": {
        "id": "08436467-1efb-4301-9c59-43f7363ca4f8"
      },
      "source": [
        "## Setup\n",
        "\n",
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89d904bc",
      "metadata": {
        "id": "89d904bc"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d83b62c",
      "metadata": {
        "id": "0d83b62c"
      },
      "source": [
        "## Section 1: Tensors are Fully Compatible with NumPy\n",
        "\n",
        "PyTorch tensors can easily be converted to and from NumPy arrays, making it simple to use PyTorch alongside existing NumPy code. Many NumPy-style operations work directly on tensors, such as indexing, slicing, and common mathematical functions.\n",
        "\n",
        "| Code | Description |\n",
        "| :-- | :-- |\n",
        "| `x.numpy()` | Convert a tensor to a NumPy array. |\n",
        "| `torch.tensor(arr)` | Convert a NumPy array to a tensor. |\n",
        "| `torch.from_numpy(arr)` | Convert a NumPy array to a tensor (shares memory with the original array). |\n",
        "| `x = torch.tensor(2)` <br> `float(x)` | Turn torch tensor containing scalar into float number. |\n",
        "| `x = torch.tensor(2.4)` <br> `x.item()` | Get value of tensor as standard Python number (the type is automatically recognized). |\n",
        "| `x.sum()` | Sum all elements in the tensor. |\n",
        "| `x.mean()` | Calculate the mean of all elements. |\n",
        "| `x[0]` | Index the first element. |\n",
        "| `x[1:3]` | Slice elements from index 1 to 2. |\n",
        "| `torch.matmul(A,B)` | Performs matrix multiplication on the two tensors A and B. |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b630e4f9",
      "metadata": {
        "id": "b630e4f9"
      },
      "source": [
        "**Example**: Create a tensor `x` containing the values 10, 20, 30 and convert it to a NumPy array using `.numpy()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25ef8197",
      "metadata": {
        "id": "25ef8197"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([10, 20, 30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dba369cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dba369cd",
        "outputId": "39489754-3960-4ee4-a054-750a11857ff0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([10, 20, 30])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58d1e1ea",
      "metadata": {
        "id": "58d1e1ea"
      },
      "source": [
        "**Exercise**: Create a NumPy array and convert it to a PyTorch tensor using `torch.tensor()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "927ef2c4",
      "metadata": {
        "id": "927ef2c4"
      },
      "outputs": [],
      "source": [
        "arr = np.array([1.5, 2.5, 3.5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6763f04d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6763f04d",
        "outputId": "1c32f2df-fd4d-4bb1-ecdb-f913bea6a9a5",
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.5000, 2.5000, 3.5000], dtype=torch.float64)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor(arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d5bf251",
      "metadata": {
        "id": "0d5bf251"
      },
      "source": [
        "**Exercise**: Create a NumPy array and convert it to a tensor using `torch.from_numpy()`. This method shares memory with the original array, so changes to one will affect the other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c98df26",
      "metadata": {
        "id": "0c98df26"
      },
      "outputs": [],
      "source": [
        "arr = np.array([1.0, 2.0, 3.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9999c2e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9999c2e5",
        "outputId": "c5862fc9-e78c-4628-9cc0-a9464a4b3dfb",
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 2., 3.], dtype=torch.float64)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.from_numpy(arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd972012",
      "metadata": {
        "id": "dd972012"
      },
      "source": [
        "**Exercise**: Use `.item()` to get the value of the tensor `x` below as a standard Python number."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "977df8e0",
      "metadata": {
        "id": "977df8e0"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor(3.14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcd9d791",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcd9d791",
        "outputId": "08248d5f-716d-46c3-e66f-b04334e0ecfc",
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.140000104904175"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f11f25fc",
      "metadata": {
        "id": "f11f25fc"
      },
      "source": [
        "**Exercise**: Convert the tensor object of the scalar number 5 into a float object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97a67725",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97a67725",
        "outputId": "deda677f-926d-4bcf-b9e9-e2775407da31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([5])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "820a960f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "820a960f",
        "outputId": "eb47409d-6a27-47eb-d45e-ed9b5ba70e14",
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5.0"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf4c48bb",
      "metadata": {
        "id": "cf4c48bb"
      },
      "source": [
        "**Exercise**: Calculate the sum of all elements in tensor `x`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9810190",
      "metadata": {
        "id": "a9810190"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([1.0, 2.0, 3.0, 4.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3100d0de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3100d0de",
        "outputId": "9cfe46a1-c599-42a5-b874-dd4250aeb780",
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(10.)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6af46dc5",
      "metadata": {
        "id": "6af46dc5"
      },
      "source": [
        "**Exercise**: Calculate the mean of all elements in tensor `y` below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cda93b6d",
      "metadata": {
        "id": "cda93b6d"
      },
      "outputs": [],
      "source": [
        "y = torch.tensor([2.0, 4.0, 6.0, 8.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77bad23c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77bad23c",
        "outputId": "d6ec579d-a336-47e7-d2df-460d3bc3fe66",
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a03b4a9",
      "metadata": {
        "id": "3a03b4a9"
      },
      "source": [
        "**Exercise**: Multiply tensor A with tensor B."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a6854e6",
      "metadata": {
        "id": "2a6854e6"
      },
      "outputs": [],
      "source": [
        "A = torch.tensor([[1,2], [3,4], [5,6]])\n",
        "B = torch.tensor([[7,8,9], [10,11,12]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62c51d8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62c51d8e",
        "outputId": "d8520d0e-555e-4791-9d40-0431547bdb93",
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 27,  30,  33],\n",
              "        [ 61,  68,  75],\n",
              "        [ 95, 106, 117]])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.matmul(A,B)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4003cac-b83c-496c-b16a-8a8492f1cf79",
      "metadata": {
        "id": "d4003cac-b83c-496c-b16a-8a8492f1cf79"
      },
      "source": [
        "## Section 2: Torch Tensors can Run Off of GPUs\n",
        "\n",
        "One of PyTorch's key advantages over NumPy is its ability to run computations on GPUs, which can dramatically speed up neural network training. You can check if a GPU is available, move tensors between CPU and GPU, or create tensors directly on the GPU.\n",
        "\n",
        "| Code | Description |\n",
        "| :-- | :--|\n",
        "| `x.device` | Where is the tensor stored? |\n",
        "| `torch.cuda.is_available()` | Is a GPU available? |\n",
        "| `torch.cuda.device_count()` | Number of GPUs  |\n",
        "| `torch.cuda.get_device_name()` | Name of GPUs (if any) |\n",
        "| `x = torch.tensor([1, 2, 3], device='cuda')` | Create a tensor on the GPU |\n",
        "| `x_cpu = x.to('cpu')` | Copy the tensor to the CPU. |\n",
        "| `x_gpu = x_cpu.to('cuda')` | Copy the tensor to the GPU. |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc0ca0a2",
      "metadata": {},
      "source": [
        "This section should be done in Google Colab. Open the notebook in Google Colab by clicking the button below."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "affdd68b",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "42zqvw9we5n",
      "metadata": {
        "id": "42zqvw9we5n"
      },
      "source": [
        "**Example**: Check if a GPU is available on your machine using `torch.cuda.is_available()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "r18lyr9vc67",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r18lyr9vc67",
        "outputId": "6e97db83-c333-43a1-f3a5-f1a6e957d7af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PUIZ33OrIX6o",
      "metadata": {
        "id": "PUIZ33OrIX6o"
      },
      "source": [
        "**Exercise**: Click on \"Runtime\" in the toolbar, then \"Change runtime type\", select \"T4 GPU\" and click \"Save\". The session is restarted when you change the runtime type, so run the first cell below to import the libraries again. Then, check if a GPU is available on your machine. What is the output now?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ecgxbaaI7GK",
      "metadata": {
        "id": "8ecgxbaaI7GK"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vmqCfMOuB5Qz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmqCfMOuB5Qz",
        "outputId": "706ab041-7281-423e-8bd9-76efad8d9495",
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y6m8oa6uiha",
      "metadata": {
        "id": "y6m8oa6uiha"
      },
      "source": [
        "**Exercise**: Check how many GPUs are available using `torch.cuda.device_count()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "namd1r1e82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "namd1r1e82",
        "outputId": "05d3605b-58a4-45c1-bb93-8c44eda38cba",
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wxscidw96hi",
      "metadata": {
        "id": "wxscidw96hi"
      },
      "source": [
        "**Exercise**: If a GPU is available, get the name of the GPU using `torch.cuda.get_device_name()`. If no GPU is available, this cell will produce an error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4y40nzgegp6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4y40nzgegp6",
        "outputId": "68d44a6b-530d-40df-b312-cbf017703e73",
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.get_device_name()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zwd2f72015r",
      "metadata": {
        "id": "zwd2f72015r"
      },
      "source": [
        "**Exercise**: Create a tensor `x` containing the values 1, 2, 3 and check which device it is stored on using `.device`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49fhqi4ida7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49fhqi4ida7",
        "outputId": "9bdb3d34-a083-4ce9-e374-43373386797c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([1, 2, 3])\n",
        "x.device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4p82zvuu0i",
      "metadata": {
        "id": "4p82zvuu0i"
      },
      "source": [
        "**Exercise**: If a GPU is available, move the tensor `x` to the GPU using `.to('cuda')`. If no GPU is available, this cell will produce an error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jcltdjgsds",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcltdjgsds",
        "outputId": "e33848a4-59c5-42bc-8eb1-ef6608f3119a",
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_gpu = x.to('cuda')\n",
        "x_gpu.device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8j87ywx1vke",
      "metadata": {
        "id": "8j87ywx1vke"
      },
      "source": [
        "**Exercise**: Create a tensor directly on the GPU by specifying `device='cuda'` in `torch.tensor()`. If no GPU is available, this cell will produce an error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8t0x281lhxv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t0x281lhxv",
        "outputId": "453dcaf6-f745-44f6-b962-f7678b87b4a0",
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = torch.tensor([4, 5, 6], device='cuda')\n",
        "y.device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ond47h754eh",
      "metadata": {
        "id": "ond47h754eh"
      },
      "source": [
        "**Exercise**: Move the tensor `y` created above back to the CPU using `.to('cpu')`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ex4mj7uxgyn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex4mj7uxgyn",
        "outputId": "f285c7f9-7547-4358-a007-0624990e230b",
        "tags": [
          "solution"
        ]
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_cpu = y.to('cpu')\n",
        "y_cpu.device"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fa67be0",
      "metadata": {
        "id": "8fa67be0"
      },
      "source": [
        "## (Extra, Demo) Section 3: PyTorch Can Massively Speed up Calculations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acd0aca1",
      "metadata": {},
      "source": [
        "This section should be done in Google Colab. Open the notebook in Google Colab by clicking the button below if you're not already working in Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "828e54a9",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "fa88bba3",
      "metadata": {},
      "source": [
        "**Exercise**: Run cells below to compare how long it takes to do a matrix multiplication with pure Python, Numpy, PyTorch on CPU, and PyTorch on GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "051cfeac",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WhuCmC_gGXxs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhuCmC_gGXxs",
        "outputId": "474b7031-9428-4502-a7a1-176aee04c205"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6n9P-0keG2kH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n9P-0keG2kH",
        "outputId": "7f36e832-78ca-458a-8d0c-1181779080d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix multiplication (500x500):\n",
            "  Pure Python:   14.4273 seconds\n",
            "  NumPy (CPU):   0.0041 seconds\n",
            "  PyTorch (CPU): 0.0092 seconds\n",
            "  PyTorch (GPU): 0.0002 seconds\n",
            "\n",
            "Speedups vs Pure Python:\n",
            "  NumPy:       3494x faster\n",
            "  PyTorch CPU: 1566x faster\n",
            "  PyTorch GPU: 80552x faster\n"
          ]
        }
      ],
      "source": [
        "# Large matrix multiplication comparison\n",
        "size = 500  # smaller size for pure Python because it's too slow\n",
        "\n",
        "# Create large random matrices with NumPy\n",
        "A_np = np.random.randn(size, size).astype(np.float32)\n",
        "B_np = np.random.randn(size, size).astype(np.float32)\n",
        "\n",
        "# Time pure Python (nested loops)\n",
        "A_list = A_np.tolist()\n",
        "B_list = B_np.tolist()\n",
        "\n",
        "start = time.perf_counter()\n",
        "C_python = [[sum(A_list[i][k] * B_list[k][j] for k in range(size))\n",
        "             for j in range(size)] for i in range(size)]\n",
        "python_time = time.perf_counter() - start\n",
        "\n",
        "print(f\"Matrix multiplication ({size}x{size}):\")\n",
        "print(f\"  Pure Python:   {python_time:.4f} seconds\")\n",
        "\n",
        "# Time NumPy (CPU)\n",
        "start = time.perf_counter()\n",
        "C_np = np.matmul(A_np, B_np)\n",
        "numpy_time = time.perf_counter() - start\n",
        "print(f\"  NumPy (CPU):   {numpy_time:.4f} seconds\")\n",
        "\n",
        "# Time PyTorch CPU\n",
        "A_cpu = torch.from_numpy(A_np)\n",
        "B_cpu = torch.from_numpy(B_np)\n",
        "\n",
        "start = time.perf_counter()\n",
        "C_cpu = torch.matmul(A_cpu, B_cpu)\n",
        "pytorch_cpu_time = time.perf_counter() - start\n",
        "print(f\"  PyTorch (CPU): {pytorch_cpu_time:.4f} seconds\")\n",
        "\n",
        "# Time PyTorch GPU (if available)\n",
        "if device == 'cuda':\n",
        "    A_gpu = A_cpu.to('cuda')\n",
        "    B_gpu = B_cpu.to('cuda')\n",
        "\n",
        "    # Warm-up run (first GPU call has extra overhead)\n",
        "    _ = torch.matmul(A_gpu, B_gpu)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    # Timed run\n",
        "    start = time.perf_counter()\n",
        "    C_gpu = torch.matmul(A_gpu, B_gpu)\n",
        "    torch.cuda.synchronize()  # wait for GPU to finish\n",
        "    gpu_time = time.perf_counter() - start\n",
        "\n",
        "    print(f\"  PyTorch (GPU): {gpu_time:.4f} seconds\")\n",
        "    print(f\"\\nSpeedups vs Pure Python:\")\n",
        "    print(f\"  NumPy:       {python_time/numpy_time:.0f}x faster\")\n",
        "    print(f\"  PyTorch CPU: {python_time/pytorch_cpu_time:.0f}x faster\")\n",
        "    print(f\"  PyTorch GPU: {python_time/gpu_time:.0f}x faster\")\n",
        "else:\n",
        "    print(f\"\\nSpeedups vs Pure Python:\")\n",
        "    print(f\"  NumPy:       {python_time/numpy_time:.0f}x faster\")\n",
        "    print(f\"  PyTorch CPU: {python_time/pytorch_cpu_time:.0f}x faster\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IMNf0TEiGTr0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMNf0TEiGTr0",
        "outputId": "a3ab2fea-af90-4805-f652-89e674f0c184"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix multiplication (4096x4096):\n",
            "  NumPy (CPU):   1.1602 seconds\n",
            "  PyTorch (CPU): 1.2312 seconds\n",
            "  PyTorch (GPU): 0.0467 seconds\n",
            "\n",
            "GPU is 24.9x faster than NumPy\n"
          ]
        }
      ],
      "source": [
        "# Large matrix multiplication comparison\n",
        "size = 4096\n",
        "\n",
        "# Create large random matrices with NumPy\n",
        "A_np = np.random.randn(size, size).astype(np.float32)\n",
        "B_np = np.random.randn(size, size).astype(np.float32)\n",
        "\n",
        "# Time NumPy (CPU)\n",
        "start = time.perf_counter()\n",
        "C_np = np.matmul(A_np, B_np)\n",
        "numpy_time = time.perf_counter() - start\n",
        "\n",
        "print(f\"Matrix multiplication ({size}x{size}):\")\n",
        "print(f\"  NumPy (CPU):   {numpy_time:.4f} seconds\")\n",
        "\n",
        "# Time PyTorch CPU\n",
        "A_cpu = torch.from_numpy(A_np)\n",
        "B_cpu = torch.from_numpy(B_np)\n",
        "\n",
        "start = time.perf_counter()\n",
        "C_cpu = torch.matmul(A_cpu, B_cpu)\n",
        "pytorch_cpu_time = time.perf_counter() - start\n",
        "\n",
        "print(f\"  PyTorch (CPU): {pytorch_cpu_time:.4f} seconds\")\n",
        "\n",
        "# Time PyTorch GPU (if available)\n",
        "if device == 'cuda':\n",
        "    A_gpu = A_cpu.to('cuda')\n",
        "    B_gpu = B_cpu.to('cuda')\n",
        "\n",
        "    # Warm-up run (first GPU call has extra overhead)\n",
        "    _ = torch.matmul(A_gpu, B_gpu)\n",
        "    torch.cuda.synchronize()\n",
        "\n",
        "    # Timed run\n",
        "    start = time.perf_counter()\n",
        "    C_gpu = torch.matmul(A_gpu, B_gpu)\n",
        "    torch.cuda.synchronize()  # wait for GPU to finish\n",
        "    gpu_time = time.perf_counter() - start\n",
        "\n",
        "    print(f\"  PyTorch (GPU): {gpu_time:.4f} seconds\")\n",
        "    print(f\"\\nGPU is {numpy_time/gpu_time:.1f}x faster than NumPy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1f6e55a",
      "metadata": {
        "id": "f1f6e55a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "default",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
